{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Preprocessing\n",
    "\n",
    "Read the dataset of dinosaur names and create a list of unique characters (such as a-z), and compute the dataset and vocabulary size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data= open(filename, 'r').read()\n",
    "    data=data.lower()\n",
    "    chars=list(set(data))\n",
    "    data_size, vocab_size = len(data), len(chars)\n",
    "    print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))\n",
    "    return chars,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19909 total characters and 27 unique characters in your data.\n"
     ]
    }
   ],
   "source": [
    "chars,data= read_data('data/dinos.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The characters are a-z (26 characters) plus the \"\\n\" (or newline character), which plays a role similar to the `<EOS>` (or \"End of sentence\") token.it indicates the end of the dinosaur name rather than the end of a sentence. In the cell below, we create a python dictionary (i.e., a hash table) to map each character to an index from 0-26. We also create a second python dictionary that maps each index back to the corresponding character character. This will help figure out what index corresponds to what character in the probability distribution output of the softmax layer. Below, `char_to_ix` and `ix_to_char` are the python dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix={char:i for i,char in enumerate(sorted(chars))}\n",
    "ix_to_char=np.array(sorted(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, '\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ix['\\n'], ix_to_char[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input text as integers mapped from the char_to_ix dict\n",
    "text_as_int = np.array([char_to_ix[c] for c in data ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('aachenosaurus\\n',\n",
       " array([ 1,  1,  3,  8,  5, 14, 15, 19,  1, 21, 18, 21, 19,  0]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:14],text_as_int[:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The prediction task\n",
    "\n",
    "Given a character, or a sequence of characters, what is the most probable next character? This is the task we're training the model to perform. The input to the model will be a sequence of characters, and we train the model to predict the outputâ€”the following character at each time step.\n",
    "\n",
    "Since RNNs maintain an internal state that depends on the previously seen elements, given all the characters computed until this moment, what is the next character?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training examples and targets\n",
    "Next divide the text into example sequences. Each input sequence will contain seq_length characters from the text. \n",
    "For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the right.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dinousar_names(filename):\n",
    "    with open(filename) as f:\n",
    "        dinousar_names = f.readlines()\n",
    "        dinousar_names = [x.lower().strip() for x in dinousar_names ]\n",
    "    return dinousar_names\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aachenosaurus', 'aardonyx', 'abdallahsaurus', 'abelisaurus', 'abrictosaurus']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinousar_names=read_dinousar_names('data/dinos.txt')\n",
    "dinousar_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle the examples.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle list of all dinosaur names\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(dinousar_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turiasaurus',\n",
       " 'pandoravenator',\n",
       " 'ilokelesia',\n",
       " 'chubutisaurus',\n",
       " 'quaesitosaurus']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dinousar_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sequence, duplicate and shift it to form the input and target text by using the using None as the first character to the input and from index 1 for the Y targets. the None ensures both the inputs and Targets are similar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_x_y_dataset(dinousar_names):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for name in dinousar_names:\n",
    "        x=[0] + [char_to_ix[ch] for ch in name]\n",
    "        y= x[1:] + [char_to_ix['\\n']]\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        \n",
    "    #pad with zeros for maximum length\n",
    "    X=np.array(list(itertools.zip_longest(*X, fillvalue=0))).T\n",
    "    Y=np.array(list(itertools.zip_longest(*Y, fillvalue=0))).T\n",
    "    X=X.reshape(-1,27,1)\n",
    "    \n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y= create_x_y_dataset(dinousar_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow + Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a 2 layer LSTM with each having 128 units then a softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(27,1), return_sequences=True))\n",
    "model.add(layers.LSTM(128))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))\n",
    "# Add a softmax layer with 10 output units:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 27, 128)           66560     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 27)                3483      \n",
      "=================================================================\n",
      "Total params: 201,627\n",
      "Trainable params: 201,627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.train.AdamOptimizer(0.15),\n",
    "    loss = 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample an index from a probability array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function invoked at end of each epoch. Prints generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(data) - 27 - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = data[start_index: start_index + 27]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(2):\n",
    "            x_pred = np.zeros((1, 27, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_to_ix[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred.reshape(-1,27,1), verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = ix_to_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1472/1536 [===========================>..] - ETA: 0s - loss: 1422.3292\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"govuchia\n",
      "yutyrannus\n",
      "zanabaz\"\n",
      "govuchia\n",
      "yutyrannus\n",
      "zanabazbb\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"govuchia\n",
      "yutyrannus\n",
      "zanabaz\"\n",
      "govuchia\n",
      "yutyrannus\n",
      "zanabazbb\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"govuchia\n",
      "yutyrannus\n",
      "zanabaz\"\n",
      "govuchia\n",
      "yutyrannus\n",
      "zanabazlg\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"govuchia\n",
      "yutyrannus\n",
      "zanabaz\"\n",
      "govuchia\n",
      "yutyrannus\n",
      "zanabazjf\n",
      "1536/1536 [==============================] - 6s 4ms/step - loss: 1417.4809\n",
      "Epoch 2/10\n",
      "1472/1536 [===========================>..] - ETA: 0s - loss: 1177.1895\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"rus\n",
      "asiaceratops\n",
      "asiamerica\"\n",
      "rus\n",
      "asiaceratops\n",
      "asiamericagf\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"rus\n",
      "asiaceratops\n",
      "asiamerica\"\n",
      "rus\n",
      "asiaceratops\n",
      "asiamericaee\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"rus\n",
      "asiaceratops\n",
      "asiamerica\"\n",
      "rus\n",
      "asiaceratops\n",
      "asiamericade\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"rus\n",
      "asiaceratops\n",
      "asiamerica\"\n",
      "rus\n",
      "asiaceratops\n",
      "asiamericag\n",
      "\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1177.3619\n",
      "Epoch 3/10\n",
      "1472/1536 [===========================>..] - ETA: 0s - loss: 1085.4851\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"asus\n",
      "fusuisaurus\n",
      "futabasaur\"\n",
      "asus\n",
      "fusuisaurus\n",
      "futabasaurff\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"asus\n",
      "fusuisaurus\n",
      "futabasaur\"\n",
      "asus\n",
      "fusuisaurus\n",
      "futabasaurjf\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"asus\n",
      "fusuisaurus\n",
      "futabasaur\"\n",
      "asus\n",
      "fusuisaurus\n",
      "futabasaurgl\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"asus\n",
      "fusuisaurus\n",
      "futabasaur\"\n",
      "asus\n",
      "fusuisaurus\n",
      "futabasaurfg\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1083.4945\n",
      "Epoch 4/10\n",
      "1472/1536 [===========================>..] - ETA: 0s - loss: 1078.2036\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"cedarpelta\n",
      "cedrorestes\n",
      "cent\"\n",
      "cedarpelta\n",
      "cedrorestes\n",
      "centii\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"cedarpelta\n",
      "cedrorestes\n",
      "cent\"\n",
      "cedarpelta\n",
      "cedrorestes\n",
      "centij\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"cedarpelta\n",
      "cedrorestes\n",
      "cent\"\n",
      "cedarpelta\n",
      "cedrorestes\n",
      "centld\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"cedarpelta\n",
      "cedrorestes\n",
      "cent\"\n",
      "cedarpelta\n",
      "cedrorestes\n",
      "centii\n",
      "1536/1536 [==============================] - 2s 1ms/step - loss: 1074.5297\n",
      "Epoch 5/10\n",
      "1472/1536 [===========================>..] - ETA: 0s - loss: 1072.9920\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"apnosaurus\n",
      "megaraptor\n",
      "mei\n",
      "m\"\n",
      "apnosaurus\n",
      "megaraptor\n",
      "mei\n",
      "mgd\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"apnosaurus\n",
      "megaraptor\n",
      "mei\n",
      "m\"\n",
      "apnosaurus\n",
      "megaraptor\n",
      "mei\n",
      "mif\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"apnosaurus\n",
      "megaraptor\n",
      "mei\n",
      "m\"\n",
      "apnosaurus\n",
      "megaraptor\n",
      "mei\n",
      "mfi\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"apnosaurus\n",
      "megaraptor\n",
      "mei\n",
      "m\"\n",
      "apnosaurus\n",
      "megaraptor\n",
      "mei\n",
      "mji\n",
      "1536/1536 [==============================] - 3s 2ms/step - loss: 1073.6050\n",
      "Epoch 6/10\n",
      "1472/1536 [===========================>..] - ETA: 0s - loss: 1078.6217\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"kisaurus\n",
      "palaeoctonus\n",
      "palae\"\n",
      "kisaurus\n",
      "palaeoctonus\n",
      "palaede\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"kisaurus\n",
      "palaeoctonus\n",
      "palae\"\n",
      "kisaurus\n",
      "palaeoctonus\n",
      "palaegb\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"kisaurus\n",
      "palaeoctonus\n",
      "palae\"\n",
      "kisaurus\n",
      "palaeoctonus\n",
      "palaebg\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"kisaurus\n",
      "palaeoctonus\n",
      "palae\"\n",
      "kisaurus\n",
      "palaeoctonus\n",
      "palaebf\n",
      "1536/1536 [==============================] - 3s 2ms/step - loss: 1075.4001\n",
      "Epoch 7/10\n",
      "1472/1536 [===========================>..] - ETA: 0s - loss: 1075.0860\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"nophorosaurus\n",
      "spinops\n",
      "spino\"\n",
      "nophorosaurus\n",
      "spinops\n",
      "spinoif\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"nophorosaurus\n",
      "spinops\n",
      "spino\"\n",
      "nophorosaurus\n",
      "spinops\n",
      "spinoif\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"nophorosaurus\n",
      "spinops\n",
      "spino\"\n",
      "nophorosaurus\n",
      "spinops\n",
      "spinoig\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"nophorosaurus\n",
      "spinops\n",
      "spino\"\n",
      "nophorosaurus\n",
      "spinops\n",
      "spinod\n",
      "\n",
      "1536/1536 [==============================] - 2s 2ms/step - loss: 1074.3125\n",
      "Epoch 8/10\n",
      "1472/1536 [===========================>..] - ETA: 0s - loss: 1076.6294\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"saurus\n",
      "tochisaurus\n",
      "tomodon\n",
      "\"\n",
      "saurus\n",
      "tochisaurus\n",
      "tomodon\n",
      "b\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"saurus\n",
      "tochisaurus\n",
      "tomodon\n",
      "\"\n",
      "saurus\n",
      "tochisaurus\n",
      "tomodon\n",
      "\n",
      "f\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"saurus\n",
      "tochisaurus\n",
      "tomodon\n",
      "\"\n",
      "saurus\n",
      "tochisaurus\n",
      "tomodon\n",
      "bl\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"saurus\n",
      "tochisaurus\n",
      "tomodon\n",
      "\"\n",
      "saurus\n",
      "tochisaurus\n",
      "tomodon\n",
      "e\n",
      "\n",
      "1536/1536 [==============================] - 2s 2ms/step - loss: 1075.5393\n",
      "Epoch 9/10\n",
      "1472/1536 [===========================>..] - ETA: 0s - loss: 1079.5083\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"n\n",
      "iguanoides\n",
      "skeleton\n",
      "iguan\"\n",
      "n\n",
      "iguanoides\n",
      "skeleton\n",
      "iguanff\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"n\n",
      "iguanoides\n",
      "skeleton\n",
      "iguan\"\n",
      "n\n",
      "iguanoides\n",
      "skeleton\n",
      "iguanfd\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"n\n",
      "iguanoides\n",
      "skeleton\n",
      "iguan\"\n",
      "n\n",
      "iguanoides\n",
      "skeleton\n",
      "iguanbj\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"n\n",
      "iguanoides\n",
      "skeleton\n",
      "iguan\"\n",
      "n\n",
      "iguanoides\n",
      "skeleton\n",
      "iguanif\n",
      "1536/1536 [==============================] - 2s 2ms/step - loss: 1075.4796\n",
      "Epoch 10/10\n",
      "1472/1536 [===========================>..] - ETA: 0s - loss: 1073.8776\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ryphorosaurus\n",
      "draconyx\n",
      "drac\"\n",
      "ryphorosaurus\n",
      "draconyx\n",
      "draci\n",
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ryphorosaurus\n",
      "draconyx\n",
      "drac\"\n",
      "ryphorosaurus\n",
      "draconyx\n",
      "dracbi\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"ryphorosaurus\n",
      "draconyx\n",
      "drac\"\n",
      "ryphorosaurus\n",
      "draconyx\n",
      "drac\n",
      "j\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"ryphorosaurus\n",
      "draconyx\n",
      "drac\"\n",
      "ryphorosaurus\n",
      "draconyx\n",
      "dracb\n",
      "\n",
      "1536/1536 [==============================] - 2s 2ms/step - loss: 1075.5831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc0dc4295c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y, batch_size=64, epochs=10,callbacks=[print_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try a prediction with custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.zeros(shape=(len(chars),len(chars),1), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we add some few characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.random.choice(26, (27,27,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "    preds.append(sample(model.predict(X_test)[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n",
      "f\n",
      "l\n",
      "\n",
      "\n",
      "d\n",
      "d\n",
      "\n",
      "\n",
      "i\n",
      "j\n",
      "l\n",
      "j\n",
      "g\n",
      "f\n",
      "i\n",
      "\n",
      "\n",
      "i\n",
      "b\n",
      "f\n",
      "l\n",
      "i\n",
      "i\n",
      "l\n",
      "\n",
      "\n",
      "e\n",
      "\n",
      "\n",
      "g\n",
      "g\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(ix_to_char[preds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
